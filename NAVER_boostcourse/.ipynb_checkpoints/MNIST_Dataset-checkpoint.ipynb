{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8210366-817d-43e3-8643-d0f29ba43717",
   "metadata": {},
   "source": [
    "# SOURCE CODE FOR TORCHVISION.DATASETS.MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b7ec6bc-2269-42fc-af72-807be1911e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs\n",
    "import os\n",
    "import os.path\n",
    "import shutil\n",
    "import string\n",
    "import sys\n",
    "import warnings\n",
    "from typing import Any, Callable, Dict, List, Optional, Tuple\n",
    "from urllib.error import URLError\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from PIL import Image\n",
    "\n",
    "# from .utils import _flip_byte_order, check_integrity, download_and_extract_archive, extract_archive, verify_str_arg\n",
    "from torchvision.datasets.vision import VisionDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa411c0f-5ece-4581-94bf-8f7924956e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNIST(VisionDataset):\n",
    "    mirrors = [\n",
    "        \"http://yann.lecun.com/exdb/mnist/\",\n",
    "        \"https://ossci-datasets.s3.amazonaws.com/mnist/\",\n",
    "    ]\n",
    "    \n",
    "    resources = [\n",
    "        (\"train-images-idx3-ubyte.gz\", \"f68b3c2dcbeaaa9fbdd348bbdeb94873\"),\n",
    "        (\"train-labels-idx1-ubyte.gz\", \"d53e105ee54ea40749a09fcbcd1e9432\"),\n",
    "        (\"t10k-images-idx3-ubyte.gz\", \"9fb629c4189551a2d022fa330f9573f3\"),\n",
    "        (\"t10k-labels-idx1-ubyte.gz\", \"ec29112dd5afa0611ce80d1b7f02629c\"),\n",
    "    ]\n",
    "    \n",
    "    training_file = \"training.pt\"\n",
    "    test_file = \"test.pt\"\n",
    "    classes = [\n",
    "        \"0 - zero\",\n",
    "        \"1 - one\",\n",
    "        \"2 - two\",\n",
    "        \"3 - three\",\n",
    "        \"4 - four\",\n",
    "        \"5 - five\",\n",
    "        \"6 - six\",\n",
    "        \"7 - seven\",\n",
    "        \"8 - eight\",\n",
    "        \"9 - nine\",\n",
    "    ]\n",
    "    \n",
    "    @property\n",
    "    def train_labels(self):\n",
    "        warnings.warn(\"train_labels has been renamed targets\")\n",
    "        return self.targets\n",
    "    \n",
    "    @property\n",
    "    def test_labels(self):\n",
    "        warnings.warn(\"test_labels has been renamed targets\")\n",
    "        return self.targets\n",
    "    \n",
    "    @property\n",
    "    def train_data(self):\n",
    "        warnings.warn(\"train_data has been renamed data\")\n",
    "        return self.data\n",
    "    \n",
    "    @property\n",
    "    def test_data(self):\n",
    "        warnings.warn(\"test_data has been renamed data\")\n",
    "        return self.data\n",
    "    \n",
    "    def __init__(self,\n",
    "                 root: str,\n",
    "                 train: bool = True,\n",
    "                 transform: Optional[Callable] = None,\n",
    "                 target_transform: Optional[Callable] = None,\n",
    "                 download: bool = False,\n",
    "                ) -> None:\n",
    "        super().__init__(root, transform=transform, target_transform=target_transform)\n",
    "        self.train = train # training set or test set\n",
    "        \n",
    "        if self._check_legacy_exist():\n",
    "            self.data, self.targets = self._load_legacy_data()\n",
    "            return\n",
    "        \n",
    "        if download:\n",
    "            self.download()\n",
    "            \n",
    "        if not self._check_exists():\n",
    "            raise RuntimeError(\"Dataset not found. You can use download=True to download it\")\n",
    "            \n",
    "        self.data, self.targets = self._load_data()\n",
    "        \n",
    "    def _check_legacy_exist(self):\n",
    "        processed_folder_exists = os.path.exists(self.processed_folder)\n",
    "        if not processed_folder_exists:\n",
    "            return False\n",
    "        \n",
    "        return all(\n",
    "            check_integrity(os.path.join(self.processed_folder, file)) for file in (self.training_file, self.test_file)\n",
    "        )\n",
    "    \n",
    "    def _load_legacy_data(self):\n",
    "        # This is for BC only. We no longer cache the daa in a custom binary, but simply read from the raw data\n",
    "        \n",
    "        #directly.\n",
    "        data_file = self.training_file if self.train else self.test_file\n",
    "        return torch.load(os.path.join(self.processed_folder, data_file))\n",
    "    \n",
    "    def _load_data(self):\n",
    "        image_file = f\"{'train' if self.train else 't10k'}-images-idx3-ubyte\"\n",
    "        data = read_image_file(os.path.join(self.raw_folder, image_file))\n",
    "        \n",
    "        label_file = f\"{'train' if self.train else 't10k'}-labels.idx1-ubyte\"\n",
    "        targets = read_label_file(os.path.join(self.raw_folder, label_file))\n",
    "        \n",
    "        return data, targets\n",
    "    \n",
    "    def __getitem__(self, index: int) -> Tuple[Any, Any]:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            index (int): Index\n",
    "            \n",
    "        Returns:\n",
    "            tuple: (image, target) where target is index of the target class.\n",
    "        \"\"\"\n",
    "        img, target = self.data[index], int(self.targets[index])\n",
    "        \n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
